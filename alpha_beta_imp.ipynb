def alphaBeta(self, node, depth, alpha, beta, maximizingPlayer):  # Alpha-Beta Pruning # noqa
        if node.current_winner:
            return {'position': None,
                    'score': 1} if node.current_winner == 'X' else {'position': None, 'score': -1} if node.current_winner == 'O' else {'position': None, 'score': 0}  # X is maximizingPlayer, O is minimizingPlayer # noqa
        elif not node.empty_squares():
            return {'position': None, 'score': 0}

        if maximizingPlayer:
            maxEval = {'position': None, 'score': -math.inf}
            for move in node.available_moves():
                child = node
                child.make_move(move, 'X')
                eval = self.alphaBeta(child, depth-1, alpha, beta, False)
                if eval['score'] > maxEval['score']:
                    maxEval['position'] = move
                    maxEval['score'] = eval['score']
                alpha = max(alpha, eval['score'])
                if beta <= alpha:
                    break
            return maxEval
        else:
            minEval = {'position': None, 'score': math.inf}
            for move in node.available_moves():
                child = node
                child.make_move(move, 'O')
                eval = self.alphaBeta(child, depth-1, alpha, beta, True)
                if eval['score'] < minEval['score']:
                    minEval['position'] = move
                    minEval['score'] = eval['score']
                beta = min(beta, eval['score'])
                if beta <= alpha:
                    break
            return minEval
